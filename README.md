
# Prithvi-Complimentary Adaptive Fusion Encoder (CAFE)
### Unlocking the full potential of multi-band satellite imagery for flood inundation mapping

The **Prithvi-CAFE** framework introduces a powerful *adaptive hybrid encoder* that fuses **Transformer-based global reasoning (Prithvi-EO-2.0)** with **CNN-based local spatial sensitivity**, enabling high-resolution, reliable flood inundation mapping across multi-channel/sensor inputs.

Prithvi-CAFE integrates:

- ğŸŒ **Prithvi-EO-2.0 (600M) backbone with lightweight Adapters**  
- ğŸ” **Multi-scale multi-stage fusion of ViT + CNN via FAT-Net**  
- ğŸ§  **Terratorch-compatible custom UPerNet decoders**  
- ğŸ“¡ **Support for any number of input channels (Sentinel-1/2, PlanetScope, DEM, etc.)**  
- âš¡ **End-to-end PyTorch Lightning training + testing pipeline**


# ğŸ“¦ Installation

```bash
git clone https://github.com/<your_username>/<your_repo>.git
cd <your_repo>

pip install -r requirements.txt
```

### Required libraries
- terratorch  
- pytorch-lightning  
- torchmetrics  
- rasterio  
- albumentations  

---

# ğŸ“‚ Dataset Structure

```
dataset_root/
â”‚
â”œâ”€â”€ img_dir/
â”‚     â”œâ”€â”€ train/
â”‚     â”œâ”€â”€ val/
â”‚     â””â”€â”€ test/
â”‚
â””â”€â”€ ann_dir/
      â”œâ”€â”€ train/
      â”œâ”€â”€ val/
      â””â”€â”€ test/
```

- Images: multi-band satellite stacks (TIF)  
- Masks:  
  - 0 = background  
  - 1 = flood  
  - -1 = ignore (not used in loss/metrics)

---

# ğŸ‹ï¸ Training

```bash
python main.py
```

---

# ğŸ” Inference Example

```python
best_ckpt_path = ".../epoch-89-val_jacc-0.9115.ckpt"

model = SemanticSegmentationTask.load_from_checkpoint(
    best_ckpt_path,
    model_args=model.hparams.model_args,
    model_factory=model.hparams.model_factory,
)

preds = torch.argmax(logits, dim=1)
```

---

# ğŸ§  Conceptual Overview

### Prithvi-CAFE = Prithvi Transformer + CNN + Adaptive Fusion

- Prithvi-EO-2.0 extracts global contextual features  
- Residual CNN + CBAM captures spatial/local texture cues  
- FAT-Net aligns and fuses multi-scale features  
- Decoder reconstructs dense segmentation at full resolution  

---

